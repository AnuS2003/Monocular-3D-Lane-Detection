{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a2d1ec1-dff4-4771-91e2-6ad40819f673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Device name: NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim, amp\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "from PIL import Image\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "\n",
    "# Check if a GPU is available and set the device\n",
    "assert torch.cuda.is_available(), \"GPU not detected! Ensure your environment has a CUDA-compatible GPU.\"\n",
    "device = torch.device(\"cuda\")\n",
    "print(\"Using device:\", device)\n",
    "print(\"Device name:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3b8d5e1-6970-44bb-b1fb-12e198e5220e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(x)  \n\u001b[0;32m     25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mLaneDataset\u001b[39;00m(\u001b[43mdataset\u001b[49m):\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, frames_dir, masks_dir, transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     29\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframes_dir \u001b[38;5;241m=\u001b[39m frames_dir\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "class LaneAttentionBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(LaneAttentionBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        attention = torch.sigmoid(self.conv1(x))\n",
    "        x = self.conv2(x)\n",
    "        x = x * attention\n",
    "        return x\n",
    "\n",
    "class LaneATT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LaneATT, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=1, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x))) \n",
    "        x = self.pool(F.relu(self.conv2(x)))  \n",
    "        x = self.conv3(x)  \n",
    "        return x\n",
    "\n",
    "class LaneDataset(dataset):\n",
    "    def __init__(self, frames_dir, masks_dir, transform=None):\n",
    "        self.frames_dir = frames_dir\n",
    "        self.masks_dir = masks_dir\n",
    "        self.transform = transform\n",
    "        self.frames = sorted(os.listdir(frames_dir))\n",
    "        self.masks = sorted(os.listdir(masks_dir))\n",
    "        assert len(self.frames) == len(self.masks), \"Number of frames and masks should be the same\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.frames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        frame_path = os.path.join(self.frames_dir, self.frames[idx])\n",
    "        mask_path = os.path.join(self.masks_dir, self.masks[idx])\n",
    "        frame = Image.open(frame_path).convert('RGB') \n",
    "        mask = Image.open(mask_path).convert('L') \n",
    "\n",
    "        if self.transform:\n",
    "            frame = self.transform(frame)\n",
    "            mask = self.transform(mask)\n",
    "\n",
    "        return frame, mask\n",
    "\n",
    "# Define transformations for data augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(degrees=5),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Set paths\n",
    "frames_dir = r'C:\\Users\\Stephen Fernandes\\Desktop\\ProjEct\\training\\frames'\n",
    "masks_dir = r'C:\\Users\\Stephen Fernandes\\Desktop\\ProjEct\\training\\lane-masks'\n",
    "\n",
    "# Load the dataset\n",
    "dataset = LaneDataset(frames_dir, masks_dir, transform=transform)\n",
    "train_loader = DataLoader(dataset, batch_size=16, shuffle=True, num_workers=4, pin_memory=True, prefetch_factor=2, persistent_workers=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470e1408-9cb6-4e61-a913-e9b7642f736f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
